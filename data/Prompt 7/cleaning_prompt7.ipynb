{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string # For punctuation\n",
    "import re # Regular expressions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer # Lemmatization\n",
    "from nltk.stem import PorterStemmer # Stemming\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           gen_essay\n",
      "0  \\n\\n\\nI was having a really hard time with mat...\n",
      "1  \\n\\nMy mom is always so patient with me. We go...\n",
      "2  \\n\\n\\nPatience is one of the most important th...\n",
      "3  \\n\\nA woman was at the doctor's office for her...\n",
      "4  \\n\\nPatience is a virtue that is often times d...\n"
     ]
    }
   ],
   "source": [
    "user_prompt7 = pd.read_csv(\"prompt7_essays.csv\", index_col=0)\n",
    "print(user_prompt7.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 9)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt7.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We have 1730 prompt 7 essays with average of 250 words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay</th>\n",
       "      <th>gen_essay_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\nI was having a really hard time with mat...</td>\n",
       "      <td>I was having a really hard time with math but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMy mom is always so patient with me. We go...</td>\n",
       "      <td>My mom is always so patient with me We go thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nPatience is one of the most important th...</td>\n",
       "      <td>Patience is one of the most important things y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nA woman was at the doctor's office for her...</td>\n",
       "      <td>A woman was at the doctors office for her annu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nPatience is a virtue that is often times d...</td>\n",
       "      <td>Patience is a virtue that is often times diffi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_essay  \\\n",
       "0  \\n\\n\\nI was having a really hard time with mat...   \n",
       "1  \\n\\nMy mom is always so patient with me. We go...   \n",
       "2  \\n\\n\\nPatience is one of the most important th...   \n",
       "3  \\n\\nA woman was at the doctor's office for her...   \n",
       "4  \\n\\nPatience is a virtue that is often times d...   \n",
       "\n",
       "                                     gen_essay_punct  \n",
       "0  I was having a really hard time with math but ...  \n",
       "1  My mom is always so patient with me We go thro...  \n",
       "2  Patience is one of the most important things y...  \n",
       "3  A woman was at the doctors office for her annu...  \n",
       "4  Patience is a virtue that is often times diffi...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Removes punctuation and newlines from sentences.\n",
    "    no_punct = [words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct = ''.join(no_punct)\n",
    "    words_wo_punct = str.strip(words_wo_punct)\n",
    "    return words_wo_punct\n",
    "\n",
    "user_prompt7['gen_essay_punct'] = user_prompt7['gen_essay'].apply(lambda x: remove_punctuation(x))\n",
    "user_prompt7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay_punct</th>\n",
       "      <th>gen_essay_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was having a really hard time with math but ...</td>\n",
       "      <td>[i, was, having, a, really, hard, time, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My mom is always so patient with me We go thro...</td>\n",
       "      <td>[my, mom, is, always, so, patient, with, me, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patience is one of the most important things y...</td>\n",
       "      <td>[patience, is, one, of, the, most, important, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A woman was at the doctors office for her annu...</td>\n",
       "      <td>[a, woman, was, at, the, doctors, office, for,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patience is a virtue that is often times diffi...</td>\n",
       "      <td>[patience, is, a, virtue, that, is, often, tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     gen_essay_punct  \\\n",
       "0  I was having a really hard time with math but ...   \n",
       "1  My mom is always so patient with me We go thro...   \n",
       "2  Patience is one of the most important things y...   \n",
       "3  A woman was at the doctors office for her annu...   \n",
       "4  Patience is a virtue that is often times diffi...   \n",
       "\n",
       "                                  gen_essay_tokenize  \n",
       "0  [i, was, having, a, really, hard, time, with, ...  \n",
       "1  [my, mom, is, always, so, patient, with, me, w...  \n",
       "2  [patience, is, one, of, the, most, important, ...  \n",
       "3  [a, woman, was, at, the, doctors, office, for,...  \n",
       "4  [patience, is, a, virtue, that, is, often, tim...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    # Split a string into words using regular expressions\n",
    "    # The \\W+ splits on one or more nonword character\n",
    "    split = re.split(\"\\W+\",text) \n",
    "    return split\n",
    "user_prompt7['gen_essay_tokenize'] = user_prompt7['gen_essay_punct'].apply(lambda x: tokenize(x.lower()))\n",
    "user_prompt7.iloc[:, 1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at first 10 frequent stop words in English\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay_tokenize</th>\n",
       "      <th>gen_essay_wo_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, was, having, a, really, hard, time, with, ...</td>\n",
       "      <td>[really, hard, time, math, teacher, told, us, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, mom, is, always, so, patient, with, me, w...</td>\n",
       "      <td>[mom, always, patient, go, many, trials, tribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[patience, is, one, of, the, most, important, ...</td>\n",
       "      <td>[patience, one, important, things, life, wheth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[a, woman, was, at, the, doctors, office, for,...</td>\n",
       "      <td>[woman, doctors, office, annual, checkup, doct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[patience, is, a, virtue, that, is, often, tim...</td>\n",
       "      <td>[patience, virtue, often, times, difficult, fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  gen_essay_tokenize  \\\n",
       "0  [i, was, having, a, really, hard, time, with, ...   \n",
       "1  [my, mom, is, always, so, patient, with, me, w...   \n",
       "2  [patience, is, one, of, the, most, important, ...   \n",
       "3  [a, woman, was, at, the, doctors, office, for,...   \n",
       "4  [patience, is, a, virtue, that, is, often, tim...   \n",
       "\n",
       "                              gen_essay_wo_stopwords  \n",
       "0  [really, hard, time, math, teacher, told, us, ...  \n",
       "1  [mom, always, patient, go, many, trials, tribu...  \n",
       "2  [patience, one, important, things, life, wheth...  \n",
       "3  [woman, doctors, office, annual, checkup, doct...  \n",
       "4  [patience, virtue, often, times, difficult, fi...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Remove stop words in each essay\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "user_prompt7['gen_essay_wo_stopwords'] = user_prompt7['gen_essay_tokenize'].apply(lambda x: remove_stopwords(x))\n",
    "user_prompt7.iloc[:, 2:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay_wo_stopwords</th>\n",
       "      <th>gen_essay_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, hard, time, math, teacher, told, us, ...</td>\n",
       "      <td>[really, hard, time, math, teacher, told, u, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mom, always, patient, go, many, trials, tribu...</td>\n",
       "      <td>[mom, always, patient, go, many, trial, tribul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[patience, one, important, things, life, wheth...</td>\n",
       "      <td>[patience, one, important, thing, life, whethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[woman, doctors, office, annual, checkup, doct...</td>\n",
       "      <td>[woman, doctor, office, annual, checkup, docto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[patience, virtue, often, times, difficult, fi...</td>\n",
       "      <td>[patience, virtue, often, time, difficult, fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              gen_essay_wo_stopwords  \\\n",
       "0  [really, hard, time, math, teacher, told, us, ...   \n",
       "1  [mom, always, patient, go, many, trials, tribu...   \n",
       "2  [patience, one, important, things, life, wheth...   \n",
       "3  [woman, doctors, office, annual, checkup, doct...   \n",
       "4  [patience, virtue, often, times, difficult, fi...   \n",
       "\n",
       "                                gen_essay_lemmatized  \n",
       "0  [really, hard, time, math, teacher, told, u, w...  \n",
       "1  [mom, always, patient, go, many, trial, tribul...  \n",
       "2  [patience, one, important, thing, life, whethe...  \n",
       "3  [woman, doctor, office, annual, checkup, docto...  \n",
       "4  [patience, virtue, often, time, difficult, fin...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    # Find the root of word using lemmatization (by dictionary definition)\n",
    "    # This takes into account the context of word used\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return text\n",
    "user_prompt7['gen_essay_lemmatized'] = user_prompt7['gen_essay_wo_stopwords'].apply(lambda x: lemmatization(x))\n",
    "user_prompt7.iloc[:, 3:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay_lemmatized</th>\n",
       "      <th>gen_essay_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, hard, time, math, teacher, told, u, w...</td>\n",
       "      <td>[realli, hard, time, math, teacher, told, us, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mom, always, patient, go, many, trial, tribul...</td>\n",
       "      <td>[mom, alway, patient, go, mani, trial, tribul,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[patience, one, important, thing, life, whethe...</td>\n",
       "      <td>[patienc, one, import, thing, life, whether, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[woman, doctor, office, annual, checkup, docto...</td>\n",
       "      <td>[woman, doctor, offic, annual, checkup, doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[patience, virtue, often, time, difficult, fin...</td>\n",
       "      <td>[patienc, virtu, often, time, difficult, find,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                gen_essay_lemmatized  \\\n",
       "0  [really, hard, time, math, teacher, told, u, w...   \n",
       "1  [mom, always, patient, go, many, trial, tribul...   \n",
       "2  [patience, one, important, thing, life, whethe...   \n",
       "3  [woman, doctor, office, annual, checkup, docto...   \n",
       "4  [patience, virtue, often, time, difficult, fin...   \n",
       "\n",
       "                                   gen_essay_stemmed  \n",
       "0  [realli, hard, time, math, teacher, told, us, ...  \n",
       "1  [mom, alway, patient, go, mani, trial, tribul,...  \n",
       "2  [patienc, one, import, thing, life, whether, p...  \n",
       "3  [woman, doctor, offic, annual, checkup, doctor...  \n",
       "4  [patienc, virtu, often, time, difficult, find,...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "def stemming(text):\n",
    "    # Find root word by stemming (leads to less words than lemming)\n",
    "    # This can chop off end of some words\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "user_prompt7['gen_essay_stemmed'] = user_prompt7['gen_essay_wo_stopwords'].apply(lambda x: stemming(x))\n",
    "user_prompt7.iloc[:, 4:].head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay</th>\n",
       "      <th>gen_essay_punct</th>\n",
       "      <th>gen_essay_tokenize</th>\n",
       "      <th>gen_essay_wo_stopwords</th>\n",
       "      <th>gen_essay_lemmatized</th>\n",
       "      <th>gen_essay_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\nI was having a really hard time with mat...</td>\n",
       "      <td>I was having a really hard time with math but ...</td>\n",
       "      <td>[i, was, having, a, really, hard, time, with, ...</td>\n",
       "      <td>[really, hard, time, math, teacher, told, us, ...</td>\n",
       "      <td>[really, hard, time, math, teacher, told, u, w...</td>\n",
       "      <td>[realli, hard, time, math, teacher, told, us, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMy mom is always so patient with me. We go...</td>\n",
       "      <td>My mom is always so patient with me We go thro...</td>\n",
       "      <td>[my, mom, is, always, so, patient, with, me, w...</td>\n",
       "      <td>[mom, always, patient, go, many, trials, tribu...</td>\n",
       "      <td>[mom, always, patient, go, many, trial, tribul...</td>\n",
       "      <td>[mom, alway, patient, go, mani, trial, tribul,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nPatience is one of the most important th...</td>\n",
       "      <td>Patience is one of the most important things y...</td>\n",
       "      <td>[patience, is, one, of, the, most, important, ...</td>\n",
       "      <td>[patience, one, important, things, life, wheth...</td>\n",
       "      <td>[patience, one, important, thing, life, whethe...</td>\n",
       "      <td>[patienc, one, import, thing, life, whether, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nA woman was at the doctor's office for her...</td>\n",
       "      <td>A woman was at the doctors office for her annu...</td>\n",
       "      <td>[a, woman, was, at, the, doctors, office, for,...</td>\n",
       "      <td>[woman, doctors, office, annual, checkup, doct...</td>\n",
       "      <td>[woman, doctor, office, annual, checkup, docto...</td>\n",
       "      <td>[woman, doctor, offic, annual, checkup, doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nPatience is a virtue that is often times d...</td>\n",
       "      <td>Patience is a virtue that is often times diffi...</td>\n",
       "      <td>[patience, is, a, virtue, that, is, often, tim...</td>\n",
       "      <td>[patience, virtue, often, times, difficult, fi...</td>\n",
       "      <td>[patience, virtue, often, time, difficult, fin...</td>\n",
       "      <td>[patienc, virtu, often, time, difficult, find,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_essay  \\\n",
       "0  \\n\\n\\nI was having a really hard time with mat...   \n",
       "1  \\n\\nMy mom is always so patient with me. We go...   \n",
       "2  \\n\\n\\nPatience is one of the most important th...   \n",
       "3  \\n\\nA woman was at the doctor's office for her...   \n",
       "4  \\n\\nPatience is a virtue that is often times d...   \n",
       "\n",
       "                                     gen_essay_punct  \\\n",
       "0  I was having a really hard time with math but ...   \n",
       "1  My mom is always so patient with me We go thro...   \n",
       "2  Patience is one of the most important things y...   \n",
       "3  A woman was at the doctors office for her annu...   \n",
       "4  Patience is a virtue that is often times diffi...   \n",
       "\n",
       "                                  gen_essay_tokenize  \\\n",
       "0  [i, was, having, a, really, hard, time, with, ...   \n",
       "1  [my, mom, is, always, so, patient, with, me, w...   \n",
       "2  [patience, is, one, of, the, most, important, ...   \n",
       "3  [a, woman, was, at, the, doctors, office, for,...   \n",
       "4  [patience, is, a, virtue, that, is, often, tim...   \n",
       "\n",
       "                              gen_essay_wo_stopwords  \\\n",
       "0  [really, hard, time, math, teacher, told, us, ...   \n",
       "1  [mom, always, patient, go, many, trials, tribu...   \n",
       "2  [patience, one, important, things, life, wheth...   \n",
       "3  [woman, doctors, office, annual, checkup, doct...   \n",
       "4  [patience, virtue, often, times, difficult, fi...   \n",
       "\n",
       "                                gen_essay_lemmatized  \\\n",
       "0  [really, hard, time, math, teacher, told, u, w...   \n",
       "1  [mom, always, patient, go, many, trial, tribul...   \n",
       "2  [patience, one, important, thing, life, whethe...   \n",
       "3  [woman, doctor, office, annual, checkup, docto...   \n",
       "4  [patience, virtue, often, time, difficult, fin...   \n",
       "\n",
       "                                   gen_essay_stemmed  \n",
       "0  [realli, hard, time, math, teacher, told, us, ...  \n",
       "1  [mom, alway, patient, go, mani, trial, tribul,...  \n",
       "2  [patienc, one, import, thing, life, whether, p...  \n",
       "3  [woman, doctor, offic, annual, checkup, doctor...  \n",
       "4  [patienc, virtu, often, time, difficult, find,...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in user_prompt7.columns:\n",
    "    for idx, row in user_prompt7.iterrows():\n",
    "        row[col] = \" \".join(row[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt7[\"Essay_set_id\"] = [7 for i in range(user_prompt7.shape[0])]\n",
    "user_prompt7[\"Essay_id\"] = [x for x in range(len(user_prompt7))]\n",
    "user_prompt7[\"Essay\"] = user_prompt7[\"gen_essay_stemmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1569, 28)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_excel(\"../asap_aes_data.xlsx\")\n",
    "scores = scores[scores[\"essay_set\"] == 7]\n",
    "scores = scores[scores[[\"rater1_domain1\", \"rater2_domain1\", \"domain1_score\"]].notna()]\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>17834</td>\n",
       "      <td>7</td>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>17836</td>\n",
       "      <td>7</td>\n",
       "      <td>I am not a patience person, like I can’t sit i...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>17837</td>\n",
       "      <td>7</td>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>17838</td>\n",
       "      <td>7</td>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>17839</td>\n",
       "      <td>7</td>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "10686     17834          7  Patience is when your waiting .I was patience ...   \n",
       "10687     17836          7  I am not a patience person, like I can’t sit i...   \n",
       "10688     17837          7  One day I was at basketball practice and I was...   \n",
       "10689     17838          7  I going to write about a time when I went to t...   \n",
       "10690     17839          7  It can be very hard for somebody to be patient...   \n",
       "\n",
       "       rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "10686             8.0             7.0             NaN           15.0   \n",
       "10687             6.0             7.0             NaN           13.0   \n",
       "10688             7.0             8.0             NaN           15.0   \n",
       "10689             8.0             9.0             NaN           17.0   \n",
       "10690             7.0             6.0             NaN           13.0   \n",
       "\n",
       "       rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "10686             NaN             NaN            NaN  ...            2.0   \n",
       "10687             NaN             NaN            NaN  ...            2.0   \n",
       "10688             NaN             NaN            NaN  ...            2.0   \n",
       "10689             NaN             NaN            NaN  ...            2.0   \n",
       "10690             NaN             NaN            NaN  ...            1.0   \n",
       "\n",
       "       rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "10686            2.0            NaN            NaN            NaN   \n",
       "10687            1.0            NaN            NaN            NaN   \n",
       "10688            2.0            NaN            NaN            NaN   \n",
       "10689            3.0            NaN            NaN            NaN   \n",
       "10690            2.0            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "10686            NaN            NaN            NaN            NaN   \n",
       "10687            NaN            NaN            NaN            NaN   \n",
       "10688            NaN            NaN            NaN            NaN   \n",
       "10689            NaN            NaN            NaN            NaN   \n",
       "10690            NaN            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait6  \n",
       "10686            NaN  \n",
       "10687            NaN  \n",
       "10688            NaN  \n",
       "10689            NaN  \n",
       "10690            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay_id</th>\n",
       "      <th>Essay_set_id</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>realli hard time math teacher told us would ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>mom alway patient go mani trial tribul famili ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>patienc one import thing life whether person l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>woman doctor offic annual checkup doctor ask t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>patienc virtu often time difficult find one st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essay_id  Essay_set_id                                              Essay\n",
       "0         0             7  realli hard time math teacher told us would ta...\n",
       "1         1             7  mom alway patient go mani trial tribul famili ...\n",
       "2         2             7  patienc one import thing life whether person l...\n",
       "3         3             7  woman doctor offic annual checkup doctor ask t...\n",
       "4         4             7  patienc virtu often time difficult find one st..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_prompt7.to_csv(\"chatgpt_essay_set_7.csv\", columns=[\"Essay_id\", \"Essay_set_id\", \"Essay\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Chat-GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\nI was having a really hard time with mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMy mom is always so patient with me. We go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nPatience is one of the most important th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nA woman was at the doctor's office for her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nPatience is a virtue that is often times d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_essay\n",
       "0  \\n\\n\\nI was having a really hard time with mat...\n",
       "1  \\n\\nMy mom is always so patient with me. We go...\n",
       "2  \\n\\n\\nPatience is one of the most important th...\n",
       "3  \\n\\nA woman was at the doctor's office for her...\n",
       "4  \\n\\nPatience is a virtue that is often times d..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_prompt7 = pd.read_csv(\"../Prompt 7/../chatgpt_prompt7_essays.csv\", index_col=0)\n",
    "chatgpt_prompt7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_prompt7['gen_essay_punct'] = chatgpt_prompt7['gen_essay'].apply(lambda x: remove_punctuation(x))\n",
    "chatgpt_prompt7['gen_essay_tokenize'] = chatgpt_prompt7['gen_essay_punct'].apply(lambda x: tokenize(x.lower()))\n",
    "chatgpt_prompt7['gen_essay_wo_stopwords'] = chatgpt_prompt7['gen_essay_tokenize'].apply(lambda x: remove_stopwords(x))\n",
    "chatgpt_prompt7['gen_essay_lemmatized'] = chatgpt_prompt7['gen_essay_wo_stopwords'].apply(lambda x: lemmatization(x))\n",
    "chatgpt_prompt7['gen_essay_stemmed'] = chatgpt_prompt7['gen_essay_wo_stopwords'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in chatgpt_prompt7.columns:\n",
    "    for idx, row in chatgpt_prompt7.iterrows():\n",
    "        row[col] = \" \".join(row[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_prompt7[\"Essay_set_id\"] = [7 for i in range(chatgpt_prompt7.shape[0])]\n",
    "chatgpt_prompt7[\"Essay_id\"] = [x for x in range(len(chatgpt_prompt7))]\n",
    "chatgpt_prompt7[\"Essay\"] = chatgpt_prompt7[\"gen_essay_stemmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_prompt7.to_csv(\"chatgpt_essay_set_7.csv\", columns=[\"Essay_id\", \"Essay_set_id\", \"Essay\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
